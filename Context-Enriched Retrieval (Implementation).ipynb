{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa0417-85b2-46c1-8d58-1edeb2551569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "import fitz\n",
    "import numpy as np\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd9c41-ae95-45fc-b1f9-6894cdd75ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract all text from a given PDF file.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        text = \"\\n\".join(page.get_text() for page in doc)\n",
    "        return text\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to extract text from PDF: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5436fa-89e8-4efd-a716-324161c35d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"./dataset/health supplements/1. dietary supplements - for whom.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc1375-e524-4c39-b20a-0f7010c0a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82608ced-241b-4c1e-ac36-1b2085a03a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, chunk_size: int, overlap: int) -> List[int]:\n",
    "    \"\"\"\n",
    "    Splits the given text into overlapping chunks.\n",
    "\n",
    "    Args:\n",
    "        text (str): The complete text to split.\n",
    "        chunk_size (int): Number of characters per chunk.\n",
    "        overlap (int): Number of overlapping characters between chunks.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of text chunks.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start += chunk_size - overlap\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d845f097-f6cd-46e8-80dc-33a7251051c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 300\n",
    "chunk_overlap = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77d9231-f48b-40dd-adb9-e19daa3bd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_text(text, chunk_size, chunk_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796cbe6e-ad15-4bae-8477-a7ede2bc20fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(chunks: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates embeddings for a list of text chunks.\n",
    "\n",
    "    Args:\n",
    "        chunks (List[str]): List of text chunks.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Matrix of embeddings.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return np.array(embedding_client.embed_documents(chunks))\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Embedding generation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e1b80-ab28-45ba-8c1a-fe0bb7cf86f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_client = OllamaEmbeddings(model=\"llama3.2:3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd28c964-b229-4d25-bfcb-1db2f52dd301",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = generate_embeddings(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de219d4-7f82-41ec-b36f-618e96a7d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(\n",
    "    query: str,\n",
    "    chunks: List[str],\n",
    "    embeddings: np.ndarray,\n",
    "    top_k: int = 3,\n",
    "    context_window: int = 1,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Performs semantic search and returns top-k relevant chunks with contextual neighbors.\n",
    "\n",
    "    Args:\n",
    "        query (str): User query.\n",
    "        chunks (List[str]): Original text chunks.\n",
    "        embeddings (np.ndarray): Precomputed embeddings.\n",
    "        top_k (int): Number of each matches to retrieve.\n",
    "        context_window (int): Number of neighbor chunks to include before and after.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Retrieved chunks with added context.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query_embedding = np.array(embedding_client.embed_query(query)).reshape(1, -1)\n",
    "        similarities = cosine_similarity(query_embedding, embeddings).flatten()\n",
    "        top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "\n",
    "        context_chunks = set()\n",
    "        for idx in top_indices:\n",
    "            for i in range(idx - context_window, idx + context_window + 1):\n",
    "                if 0 <= i < len(chunks):\n",
    "                    context_chunks.add(i)\n",
    "\n",
    "        return [chunks[i] for i in sorted(context_chunks)]\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Context-aware search failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5da798-51d6-4f09-9c10-8e507cfb6bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the main idea of the document?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c5a67-b649-49c1-b60e-f96682e65acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_chunks = retrieve_relevant_chunks(query, chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22791f13-a888-4db9-a06a-62b72c4a27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_context(chunks: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Concatenates a list of chunks into a single string as context.\n",
    "\n",
    "    Args:\n",
    "        chunks (List[str]): List of text chunks.\n",
    "\n",
    "    Returns:\n",
    "        str: Concatenated context string.\n",
    "    \"\"\"\n",
    "    return \"\\n\\n\".join(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec5b04-04bc-494b-8402-5f86c1c3e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = format_context(relevant_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc1d46-65cc-4465-beda-476beabdf8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query: str, context: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a response to a query using the retrieved context and the LLM.\n",
    "\n",
    "    Args:\n",
    "        query (str): User's input question.\n",
    "        context (str): Relevant contextual information.\n",
    "\n",
    "    Returns:\n",
    "        str: Generated answer.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prompt = f\"\"\"You are a helpful assistant. Use the following context to answer the question:\n",
    "    \n",
    "        Context:\n",
    "        {context}\n",
    "        \n",
    "        Question: {query}\n",
    "        Answer:\"\"\"\n",
    "        return chat_client.invoke(prompt).content\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to generate response: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382bb6e8-fa0c-4d7b-a50c-01ae3f30c268",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_client = ChatOllama(model=\"llama3.2:3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c504af0f-1b57-4c8d-9a8e-0fd06db444ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generate_response(query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7381d516-f4cc-492b-8a72-f4f21fcb7ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Response to '{query}':\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83062d95-869a-4ae2-853d-13142a04f182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
